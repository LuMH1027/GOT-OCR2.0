{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17e33302",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/got/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from omegaconf import OmegaConf\n",
    "from GOT.utils.arguments import *\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    \"--configs\",\n",
    "    nargs=\"*\",\n",
    "    default=[\"/apps/GOT-OCR2.0/configs/got_test.yaml\"],\n",
    "    help=\"Path to the config file\",\n",
    ")\n",
    "parser.add_argument('--local_rank', type=int, default=-1,\n",
    "                    help='Used for distributed training')  # ✅ 添加这一行\n",
    "args = parser.parse_args([])\n",
    "\n",
    "config_list = [OmegaConf.load(c) for c in args.configs]\n",
    "config = OmegaConf.merge(*config_list)\n",
    "# model_args, data_args, training_args = parser.parse_yaml_file(\n",
    "#     \"configs/got.yaml\")\n",
    "# config = OmegaConf.load(\"configs/got.yaml\")\n",
    "# 分别提取字段构造 dataclass\n",
    "model_args = ModelArguments(\n",
    "    **{k: v for k, v in config.items() if k in ModelArguments.__dataclass_fields__}\n",
    ")\n",
    "data_args = DataArguments(\n",
    "    **{k: v for k, v in config.items() if k in DataArguments.__dataclass_fields__}\n",
    ")\n",
    "training_args = TrainingArguments(\n",
    "    **{k: v for k, v in config.items() if k in TrainingArguments.__dataclass_fields__}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b909ff43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GOTQwenForCausalLM(\n",
       "  (model): GOTQwenModel(\n",
       "    (embed_tokens): Embedding(151860, 1024)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1024,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1024,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((1024,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "    (vision_tower_high): ImageEncoderViT(\n",
       "      (patch_embed): PatchEmbed(\n",
       "        (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (blocks): ModuleList(\n",
       "        (0-11): 12 x Block(\n",
       "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (neck): Sequential(\n",
       "        (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): LayerNorm2d()\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (3): LayerNorm2d()\n",
       "      )\n",
       "      (net_2): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (net_3): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (mm_projector_vary): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=151860, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from GOT.model import *\n",
    "# 假设模型已实例化并在cuda\n",
    "model = GOTQwenForCausalLM.from_pretrained(\n",
    "    \"/data_8t_1/qby/GOT-OCR2_0\", use_safetensors=True)\n",
    "model.to(\"cuda\")\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aba214c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_tower_dict = model.get_model().initialize_vision_modules(\n",
    "    vision_tower=model_args.vision_tower,\n",
    "    pretrained_stage1_model=model_args.pretrained_stage1_model,\n",
    "    freeze_vision_tower=model_args.freeze_vision_tower,\n",
    "    use_im_start_end=model_args.use_im_start_end,\n",
    "    vision_select_layer=model_args.vision_select_layer,\n",
    "    device=training_args.device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5103942a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Using 256 tokens for representing image\n",
      "WARNING:root:Formatting inputs into conversation type: mpt-fixed\n",
      "WARNING:root:Loading data...\n",
      "WARNING:root:Data from /apps/GOT-OCR2.0/test_image/longest_gpt_replies_full.json provide 1000 conversations.\n",
      "WARNING:root:1000 conversations in total.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from GOT.data.conversation_dataset_qwen import ConversationDataset\n",
    "from transformers import AutoTokenizer\n",
    "dataset_cls = ConversationDataset\n",
    "tokenizer=AutoTokenizer.from_pretrained(\n",
    "    \"/data_8t_1/qby/GOT-OCR2_0\",\n",
    "    trust_remote_code=True,\n",
    "    # use_fast=False,\n",
    "    # revision=\"v1.0.0\"\n",
    ")\n",
    "data_args.image_token_len = 256\n",
    "data_args.image_processor = vision_tower_dict['image_processor']\n",
    "data_args.image_processor_high = vision_tower_dict['image_processor_high']\n",
    "data_args.use_im_start_end = model_args.use_im_start_end\n",
    "train_dataset = dataset_cls(\n",
    "    tokenizer=tokenizer,\n",
    "    datasets=data_args.train_datasets,\n",
    "    multimodal_cfg=dict(\n",
    "        sep_image_conv_front=data_args.sep_image_conv_front,\n",
    "        image_token_len=data_args.image_token_len,\n",
    "        image_aspect_ratio=data_args.image_aspect_ratio,\n",
    "        use_im_start_end=data_args.use_im_start_end,\n",
    "        image_processor=data_args.image_processor,\n",
    "        image_processor_high=data_args.image_processor_high,\n",
    "        box_limit=data_args.box_limit,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55d4f206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset: <GOT.data.conversation_dataset_qwen.ConversationDataset object at 0x7f95195f2920>\n"
     ]
    }
   ],
   "source": [
    "print(\"train_dataset:\", train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0419ff92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: torch.Size([406])\n",
      "labels: torch.Size([406])\n",
      "image: 1\n",
      "image_high: 1\n"
     ]
    }
   ],
   "source": [
    "# print(\"train_dataset[0]:\",train_dataset[0])\n",
    "for k, v in train_dataset[0].items():\n",
    "    print(f\"{k}: {v.shape if isinstance(v, torch.Tensor) else len(v)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96f1bad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<GOT.data.conversation_dataset_qwen.ConversationDataset at 0x7f95195f2920>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18eadec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from GOT.data import DataCollatorForSupervisedDataset\n",
    "# data_collator = DataCollatorForSupervisedDataset(tokenizer=tokenizer)\n",
    "# dataloader = DataLoader(train_dataset, batch_size=16, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09055bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e48e2f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae250553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in dataloader:\n",
    "#     print(batch)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e023a0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 假设你已经定义好了 dataloader\n",
    "# batch = next(iter(dataloader))\n",
    "\n",
    "# # 打印内容\n",
    "# print(batch.keys())  # 查看有哪些字段\n",
    "# print(batch['input_ids'].shape)\n",
    "# print(batch['labels'].shape)\n",
    "# print(batch['attention_mask'].shape)\n",
    "# print(len(batch['images']))  # 查看图片数量\n",
    "# print(len(batch['images'][0]))  # 查看第一张图片的数量\n",
    "# print(batch['images'][0][0].shape)  # 查看第一张图片的形状\n",
    "# print(batch['images'][0][1].shape)  # 查看第一张图片的\n",
    "# # print((batch['images'][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f4e60f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "# import torch\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # 初始化记录字典\n",
    "# field_shapes = defaultdict(list)\n",
    "\n",
    "# # 遍历整个数据集\n",
    "# for example in tqdm(train_dataset):\n",
    "#     for k, v in example.items():\n",
    "#         if isinstance(v, torch.Tensor):\n",
    "#             field_shapes[k].append(v.shape[0])\n",
    "#         elif isinstance(v, list) or isinstance(v, str):\n",
    "#             field_shapes[k].append(len(v))\n",
    "#         else:\n",
    "#             field_shapes[k].append(type(v))\n",
    "\n",
    "# # 打印每个字段的统计结果\n",
    "# for k, v_list in field_shapes.items():\n",
    "#     unique_vals = set(v_list)\n",
    "#     print(f\"{k}:\")\n",
    "#     print(f\"  Unique shapes/lengths: {unique_vals}\")\n",
    "#     print(f\"  Max: {max(v_list)}, Min: {min(v_list)}, Avg: {sum(v_list)/len(v_list):.2f}\" if all(\n",
    "#         isinstance(x, int) for x in v_list) else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6e021ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "# import torch\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # 初始化记录字典，保存长度和对应index\n",
    "# field_max = defaultdict(lambda: {'max_len': -1, 'index': -1})\n",
    "\n",
    "# for idx, example in enumerate(tqdm(train_dataset)):\n",
    "#     for k, v in example.items():\n",
    "#         length = None\n",
    "#         if isinstance(v, torch.Tensor):\n",
    "#             length = v.shape[0]\n",
    "#         elif isinstance(v, list) or isinstance(v, str):\n",
    "#             length = len(v)\n",
    "#         else:\n",
    "#             continue\n",
    "\n",
    "#         if length > field_max[k]['max_len']:\n",
    "#             field_max[k]['max_len'] = length\n",
    "#             field_max[k]['index'] = idx\n",
    "\n",
    "# print(\"字段最大长度及对应样本index:\")\n",
    "# for k, info in field_max.items():\n",
    "#     print(f\"{k}: max_len={info['max_len']}, index={info['index']}\")\n",
    "\n",
    "# # 以某个字段为例，保存最大长度样本\n",
    "# key_of_interest = 'input_ids'  # 比如你想要最长input_ids的样本\n",
    "# max_index = field_max[key_of_interest]['index']\n",
    "# longest_sample = train_dataset[max_index]\n",
    "\n",
    "# # longest_sample 就是你想保存的最大样本\n",
    "# # 你可以保存为json，或torch保存，根据需求处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "857e55b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# torch.save(longest_sample, \"longest_sample.pt\")\n",
    "longest_sample = torch.load(\"longest_sample.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8636cfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k, v in longest_sample.items():\n",
    "#     if isinstance(v, torch.Tensor):\n",
    "#         # 确保v至少有一维且长度大于600才截断\n",
    "#         if v.size(0) > 600:\n",
    "#             longest_sample[k] = v[:600]\n",
    "#         print(f\"{k}: {longest_sample[k].shape}\")\n",
    "#     elif isinstance(v, list) or isinstance(v, str):\n",
    "#         print(f\"{k}: {len(v)}\")\n",
    "#     else:\n",
    "#         print(f\"{k}: {type(v)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d381bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([151644,   8948,    198,   2610,   1265,   1795,    279,  11221,  15516,\n",
       "            323,  10339,    697,  11253,    304,   7716,     13, 151645, 151644,\n",
       "            872,    198, 151857, 151859, 151859, 151859, 151859, 151859, 151859,\n",
       "         151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859,\n",
       "         151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859,\n",
       "         151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859,\n",
       "         151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859,\n",
       "         151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859,\n",
       "         151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859,\n",
       "         151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859,\n",
       "         151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859,\n",
       "         151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859,\n",
       "         151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859,\n",
       "         151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859,\n",
       "         151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859,\n",
       "         151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859,\n",
       "         151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859,\n",
       "         151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859,\n",
       "         151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859,\n",
       "         151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859,\n",
       "         151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859,\n",
       "         151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859,\n",
       "         151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859,\n",
       "         151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859,\n",
       "         151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859,\n",
       "         151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859,\n",
       "         151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859,\n",
       "         151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859,\n",
       "         151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859,\n",
       "         151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859, 151859,\n",
       "         151859, 151859, 151859, 151859, 151859, 151859, 151859, 151858,    198,\n",
       "          93495,     25, 151645, 151644,  77091,    198,     59,  37018,     90,\n",
       "             16,  15170,     17,  11035,  50853,      7,     16,     10,     17,\n",
       "             10,     18,     10,     19,     10,     20,     10,     21,     10,\n",
       "             22,     10,     23,     10,     24,     10,     16,     15,     10,\n",
       "             16,     16,     10,     16,     17,     10,     16,     18,     10,\n",
       "             16,     19,     10,     16,     20,     10,     16,     21,     10,\n",
       "             16,     22,     10,     16,     23,     10,     16,     24,     10,\n",
       "             17,     15,  41715,   4659,  15159,     77,     59,    983,   1124,\n",
       "            258,  36958,  11035,   2359,  11520,  37018,     90,     16,  15170,\n",
       "             77,     92,  41715,  37018,  35702,   2493,  15170,     77,  11035,\n",
       "           1291,  29776,     77,     10,     17,     17,     10,     17,     18,\n",
       "             10,     17,     19,     10,     17,     20,  41715,  34840,     59,\n",
       "           2359,  11520,  10374,   1626,    585,     90,     70,   2137,     59,\n",
       "          10374,   1626,    585,     90,     71,  11035,   1291,   7257,     17,\n",
       "             22,     10,     17,     23,     10,     17,     24,     10,     18,\n",
       "             15,     10,     18,     16,     10,     18,     17,     10,     18,\n",
       "             18,     10,     18,     19,     10,     18,     20,     10,     18,\n",
       "             21,     10,     18,     22,     10,     18,     23,     10,     18,\n",
       "             24,     10,     19,     15,     10,     19,     16,     10,     19,\n",
       "             17,     10,     19,     18,     10,     19,     19,     10,     19,\n",
       "             20,     10,     19,     21,     10,     19,     22,     10,     19,\n",
       "             23,     10,     19,     24,     10,     20,     15,     10,     20,\n",
       "             16,     10,     20,     17,     10,     20,     18,     10,     20,\n",
       "             19,     10,     20,     20,     10,     20,     21,     10,     20,\n",
       "             22,     10,     20,     23,     10,     20,     24,     10,     21,\n",
       "             15,     10,     21,     16,     10,     21,     17,     10,     21,\n",
       "             18,     10,     21,     19,     10,     21,     20,     10,     21,\n",
       "             21,     10,     21,     22,     10,     21,     23,     10,     21,\n",
       "             24,     10,     22,     15,     10,     22,     16,     10,     22,\n",
       "             17,     10,     22,     18,     10,     22,     19,     10,     22,\n",
       "             20,     10,     22,     21,     10,     22,     22,     10,     22,\n",
       "             23,     10,     22,     24,     10,     23,     15,     10,     23,\n",
       "             16,     10,     23,     17,     10,     23,     18,     10,     23,\n",
       "             19,     10,     23,     20,     10,     23,     21,     10,     23,\n",
       "             22,     10,     23,     23,     10,     23,     24,     10,     24,\n",
       "             15,     10,     24,     16,     10,     24,     17,     10,     24,\n",
       "             18,     10,     24,     19,     10,     24,     20,     10,     24,\n",
       "             21,     10,     24,     22,     10,     24,     23,     10,     24,\n",
       "             24,     10,     16,     15,     15,  11730,     16,     10,     17,\n",
       "             10,     18,     10,     19,     10,     20,     10,     21,     10,\n",
       "             22,     10,     23,     10,     24,     10,     16,     15,     10,\n",
       "             16,     16,     10,     16,     17,     10,     16,     18,     10,\n",
       "             16,     19,     10,     16,     20,     10,     16,     21,     10,\n",
       "             16,     22,     10,     16,     23,     10,     16,     24,     10,\n",
       "             17,     15,     10,     17,     16,     10,     17,     17,     10,\n",
       "             17,     18,     10,     17,     19,     10,     17,     20,     10,\n",
       "             17,     21,     10,     17,     22,     10,     17,     23,     10,\n",
       "             17,     24,     10,     18,     15,     10,     18,     16,     10,\n",
       "             18,     17,     10,     18,     18,     10,     18,     19,     10,\n",
       "             18,     20,     10,     18,     21,     10,     18,     22,     10,\n",
       "             18,     23,     10,     18,     24,     10,     19,     15,     10,\n",
       "             19,     16,     10,     19,     17,     10,     19,     18,     10,\n",
       "             19,     19,     10,     19,     20,     10,     19,     21,     10,\n",
       "             19,     22,     10,     19,     23,     10,     19,     24,     10,\n",
       "             20,     15,     10,     20,     16,     10,     20,     17,     10,\n",
       "             20,     18,     10,     20,     19,     10,     20,     20,     10,\n",
       "             20,     21,     10,     20,     22,     10,     20,     23,     10,\n",
       "             20,     24,     10,     21,     15,     10,     21,     16,     10,\n",
       "             21,     17,     10,     21,     18,     10,     21,     19,     10,\n",
       "             21,     20,     10,     21,     21,     10,     21,     22,     10,\n",
       "             21,     23,     10,     21,     24,     10,     22,     15,     10,\n",
       "             22,     16,     10,     22,     17,     10,     22,     18,     10,\n",
       "             22,     19,     10,     22,     20,     10,     22,     21,     10,\n",
       "             22,     22,     10,     22,     23,     10,     22,     24,     10,\n",
       "             23,     15,     10,     23,     16,     10,     23,     17,     10,\n",
       "             23,     18,     10,     23,     19,     10,     23,     20,     10,\n",
       "             23,     21,     10,     23,     22,     10,     23,     23,     10,\n",
       "             23,     24,     10,     24,     15,     10,     24,     16,     10,\n",
       "             24,     17,     10,     24,     18,     10,     24,     19,     10,\n",
       "             24,     20,     10,     24,     21,     10,     24,     22,     10,\n",
       "             24,     23,     10,     24,     24,     10,     16,     15,     15,\n",
       "         151645]),\n",
       " 'labels': tensor([  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,     59,  37018,     90,\n",
       "             16,  15170,     17,  11035,  50853,      7,     16,     10,     17,\n",
       "             10,     18,     10,     19,     10,     20,     10,     21,     10,\n",
       "             22,     10,     23,     10,     24,     10,     16,     15,     10,\n",
       "             16,     16,     10,     16,     17,     10,     16,     18,     10,\n",
       "             16,     19,     10,     16,     20,     10,     16,     21,     10,\n",
       "             16,     22,     10,     16,     23,     10,     16,     24,     10,\n",
       "             17,     15,  41715,   4659,  15159,     77,     59,    983,   1124,\n",
       "            258,  36958,  11035,   2359,  11520,  37018,     90,     16,  15170,\n",
       "             77,     92,  41715,  37018,  35702,   2493,  15170,     77,  11035,\n",
       "           1291,  29776,     77,     10,     17,     17,     10,     17,     18,\n",
       "             10,     17,     19,     10,     17,     20,  41715,  34840,     59,\n",
       "           2359,  11520,  10374,   1626,    585,     90,     70,   2137,     59,\n",
       "          10374,   1626,    585,     90,     71,  11035,   1291,   7257,     17,\n",
       "             22,     10,     17,     23,     10,     17,     24,     10,     18,\n",
       "             15,     10,     18,     16,     10,     18,     17,     10,     18,\n",
       "             18,     10,     18,     19,     10,     18,     20,     10,     18,\n",
       "             21,     10,     18,     22,     10,     18,     23,     10,     18,\n",
       "             24,     10,     19,     15,     10,     19,     16,     10,     19,\n",
       "             17,     10,     19,     18,     10,     19,     19,     10,     19,\n",
       "             20,     10,     19,     21,     10,     19,     22,     10,     19,\n",
       "             23,     10,     19,     24,     10,     20,     15,     10,     20,\n",
       "             16,     10,     20,     17,     10,     20,     18,     10,     20,\n",
       "             19,     10,     20,     20,     10,     20,     21,     10,     20,\n",
       "             22,     10,     20,     23,     10,     20,     24,     10,     21,\n",
       "             15,     10,     21,     16,     10,     21,     17,     10,     21,\n",
       "             18,     10,     21,     19,     10,     21,     20,     10,     21,\n",
       "             21,     10,     21,     22,     10,     21,     23,     10,     21,\n",
       "             24,     10,     22,     15,     10,     22,     16,     10,     22,\n",
       "             17,     10,     22,     18,     10,     22,     19,     10,     22,\n",
       "             20,     10,     22,     21,     10,     22,     22,     10,     22,\n",
       "             23,     10,     22,     24,     10,     23,     15,     10,     23,\n",
       "             16,     10,     23,     17,     10,     23,     18,     10,     23,\n",
       "             19,     10,     23,     20,     10,     23,     21,     10,     23,\n",
       "             22,     10,     23,     23,     10,     23,     24,     10,     24,\n",
       "             15,     10,     24,     16,     10,     24,     17,     10,     24,\n",
       "             18,     10,     24,     19,     10,     24,     20,     10,     24,\n",
       "             21,     10,     24,     22,     10,     24,     23,     10,     24,\n",
       "             24,     10,     16,     15,     15,  11730,     16,     10,     17,\n",
       "             10,     18,     10,     19,     10,     20,     10,     21,     10,\n",
       "             22,     10,     23,     10,     24,     10,     16,     15,     10,\n",
       "             16,     16,     10,     16,     17,     10,     16,     18,     10,\n",
       "             16,     19,     10,     16,     20,     10,     16,     21,     10,\n",
       "             16,     22,     10,     16,     23,     10,     16,     24,     10,\n",
       "             17,     15,     10,     17,     16,     10,     17,     17,     10,\n",
       "             17,     18,     10,     17,     19,     10,     17,     20,     10,\n",
       "             17,     21,     10,     17,     22,     10,     17,     23,     10,\n",
       "             17,     24,     10,     18,     15,     10,     18,     16,     10,\n",
       "             18,     17,     10,     18,     18,     10,     18,     19,     10,\n",
       "             18,     20,     10,     18,     21,     10,     18,     22,     10,\n",
       "             18,     23,     10,     18,     24,     10,     19,     15,     10,\n",
       "             19,     16,     10,     19,     17,     10,     19,     18,     10,\n",
       "             19,     19,     10,     19,     20,     10,     19,     21,     10,\n",
       "             19,     22,     10,     19,     23,     10,     19,     24,     10,\n",
       "             20,     15,     10,     20,     16,     10,     20,     17,     10,\n",
       "             20,     18,     10,     20,     19,     10,     20,     20,     10,\n",
       "             20,     21,     10,     20,     22,     10,     20,     23,     10,\n",
       "             20,     24,     10,     21,     15,     10,     21,     16,     10,\n",
       "             21,     17,     10,     21,     18,     10,     21,     19,     10,\n",
       "             21,     20,     10,     21,     21,     10,     21,     22,     10,\n",
       "             21,     23,     10,     21,     24,     10,     22,     15,     10,\n",
       "             22,     16,     10,     22,     17,     10,     22,     18,     10,\n",
       "             22,     19,     10,     22,     20,     10,     22,     21,     10,\n",
       "             22,     22,     10,     22,     23,     10,     22,     24,     10,\n",
       "             23,     15,     10,     23,     16,     10,     23,     17,     10,\n",
       "             23,     18,     10,     23,     19,     10,     23,     20,     10,\n",
       "             23,     21,     10,     23,     22,     10,     23,     23,     10,\n",
       "             23,     24,     10,     24,     15,     10,     24,     16,     10,\n",
       "             24,     17,     10,     24,     18,     10,     24,     19,     10,\n",
       "             24,     20,     10,     24,     21,     10,     24,     22,     10,\n",
       "             24,     23,     10,     24,     24,     10,     16,     15,     15,\n",
       "         151645]),\n",
       " 'image': [tensor([[[1.9303, 1.9303, 1.9303,  ..., 1.9303, 1.9303, 1.9303],\n",
       "           [1.9303, 1.9303, 1.9303,  ..., 1.9303, 1.9303, 1.9303],\n",
       "           [1.9303, 1.9303, 1.9303,  ..., 1.9303, 1.9303, 1.9303],\n",
       "           ...,\n",
       "           [1.9303, 1.9303, 1.9303,  ..., 1.9303, 1.9303, 1.9303],\n",
       "           [1.9303, 1.9303, 1.9303,  ..., 1.9303, 1.9303, 1.9303],\n",
       "           [1.9303, 1.9303, 1.9303,  ..., 1.9303, 1.9303, 1.9303]],\n",
       "  \n",
       "          [[2.0749, 2.0749, 2.0749,  ..., 2.0749, 2.0749, 2.0749],\n",
       "           [2.0749, 2.0749, 2.0749,  ..., 2.0749, 2.0749, 2.0749],\n",
       "           [2.0749, 2.0749, 2.0749,  ..., 2.0749, 2.0749, 2.0749],\n",
       "           ...,\n",
       "           [2.0749, 2.0749, 2.0749,  ..., 2.0749, 2.0749, 2.0749],\n",
       "           [2.0749, 2.0749, 2.0749,  ..., 2.0749, 2.0749, 2.0749],\n",
       "           [2.0749, 2.0749, 2.0749,  ..., 2.0749, 2.0749, 2.0749]],\n",
       "  \n",
       "          [[2.1459, 2.1459, 2.1459,  ..., 2.1459, 2.1459, 2.1459],\n",
       "           [2.1459, 2.1459, 2.1459,  ..., 2.1459, 2.1459, 2.1459],\n",
       "           [2.1459, 2.1459, 2.1459,  ..., 2.1459, 2.1459, 2.1459],\n",
       "           ...,\n",
       "           [2.1459, 2.1459, 2.1459,  ..., 2.1459, 2.1459, 2.1459],\n",
       "           [2.1459, 2.1459, 2.1459,  ..., 2.1459, 2.1459, 2.1459],\n",
       "           [2.1459, 2.1459, 2.1459,  ..., 2.1459, 2.1459, 2.1459]]])],\n",
       " 'image_high': [tensor([[[1.9303, 1.9303, 1.9303,  ..., 1.9303, 1.9303, 1.9303],\n",
       "           [1.9303, 1.9303, 1.9303,  ..., 1.9303, 1.9303, 1.9303],\n",
       "           [1.9303, 1.9303, 1.9303,  ..., 1.9303, 1.9303, 1.9303],\n",
       "           ...,\n",
       "           [1.9303, 1.9303, 1.9303,  ..., 1.9303, 1.9303, 1.9303],\n",
       "           [1.9303, 1.9303, 1.9303,  ..., 1.9303, 1.9303, 1.9303],\n",
       "           [1.9303, 1.9303, 1.9303,  ..., 1.9303, 1.9303, 1.9303]],\n",
       "  \n",
       "          [[2.0749, 2.0749, 2.0749,  ..., 2.0749, 2.0749, 2.0749],\n",
       "           [2.0749, 2.0749, 2.0749,  ..., 2.0749, 2.0749, 2.0749],\n",
       "           [2.0749, 2.0749, 2.0749,  ..., 2.0749, 2.0749, 2.0749],\n",
       "           ...,\n",
       "           [2.0749, 2.0749, 2.0749,  ..., 2.0749, 2.0749, 2.0749],\n",
       "           [2.0749, 2.0749, 2.0749,  ..., 2.0749, 2.0749, 2.0749],\n",
       "           [2.0749, 2.0749, 2.0749,  ..., 2.0749, 2.0749, 2.0749]],\n",
       "  \n",
       "          [[2.1459, 2.1459, 2.1459,  ..., 2.1459, 2.1459, 2.1459],\n",
       "           [2.1459, 2.1459, 2.1459,  ..., 2.1459, 2.1459, 2.1459],\n",
       "           [2.1459, 2.1459, 2.1459,  ..., 2.1459, 2.1459, 2.1459],\n",
       "           ...,\n",
       "           [2.1459, 2.1459, 2.1459,  ..., 2.1459, 2.1459, 2.1459],\n",
       "           [2.1459, 2.1459, 2.1459,  ..., 2.1459, 2.1459, 2.1459],\n",
       "           [2.1459, 2.1459, 2.1459,  ..., 2.1459, 2.1459, 2.1459]]])]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longest_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0eb0a8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: torch.Size([919])\n",
      "labels: torch.Size([919])\n",
      "image: 1\n",
      "image_high: 1\n"
     ]
    }
   ],
   "source": [
    "for k,v in longest_sample.items():\n",
    "    if isinstance(v, torch.Tensor):\n",
    "        print(f\"{k}: {v.shape}\")\n",
    "    elif isinstance(v, list) or isinstance(v, str):\n",
    "        print(f\"{k}: {len(v)}\")\n",
    "    else:\n",
    "        print(f\"{k}: {type(v)}\")  # 打印其他类型的字段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4f6a460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from collections import Counter\n",
    "\n",
    "# for k, v_list in field_shapes.items():\n",
    "#     print(f\"Plotting field: {k}\")\n",
    "\n",
    "#     # 判断v_list中元素类型\n",
    "#     if all(isinstance(x, int) for x in v_list):\n",
    "#         # 连续数值，用直方图\n",
    "#         plt.figure(figsize=(8, 4))\n",
    "#         plt.hist(v_list, bins=30, color='skyblue', edgecolor='black')\n",
    "#         plt.title(f\"{k} length distribution\")\n",
    "#         plt.xlabel(\"Length\")\n",
    "#         plt.ylabel(\"Frequency\")\n",
    "#         plt.grid(True, linestyle='--', alpha=0.5)\n",
    "#         plt.show()\n",
    "\n",
    "#     elif all(isinstance(x, tuple) for x in v_list):\n",
    "#         # 形状分布，统计频次并画条形图\n",
    "#         shape_counts = Counter(v_list)\n",
    "#         shapes = list(shape_counts.keys())\n",
    "#         counts = list(shape_counts.values())\n",
    "\n",
    "#         # 把tuple转成字符串方便显示\n",
    "#         shapes_str = [str(s) for s in shapes]\n",
    "\n",
    "#         plt.figure(figsize=(10, 5))\n",
    "#         plt.bar(range(len(counts)), counts,\n",
    "#                 color='lightcoral', edgecolor='black')\n",
    "#         plt.xticks(range(len(counts)), shapes_str, rotation=45, ha='right')\n",
    "#         plt.title(f\"{k} shape distribution\")\n",
    "#         plt.xlabel(\"Shape\")\n",
    "#         plt.ylabel(\"Frequency\")\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()\n",
    "\n",
    "#     else:\n",
    "#         print(f\"Skipped field {k} with unsupported type for plotting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "635aa38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "# 假设 longest_sample 是字典，包含键 'input_ids', 'attention_mask', 'labels', 'images'\n",
    "# input_ids, attention_mask, labels是tensor，images是list或tensor\n",
    "# batch_size = 16\n",
    "\n",
    "\n",
    "def make_batch(sample, batch_size):\n",
    "    batch = {}\n",
    "    for k, v in sample.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            batch[k] = v.unsqueeze(0).repeat(batch_size, *([1] * (v.dim())))\n",
    "        elif isinstance(v, list):\n",
    "            # 假设 images 是 list of tensors，简单重复list内容\n",
    "            batch[k] = v * batch_size  # 复制列表，batch_size倍\n",
    "        else:\n",
    "            # 其他情况，简单复制\n",
    "            batch[k] = [v] * batch_size\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "113423ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0622a1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import default_data_collator\n",
    "from GOT.data import DataCollatorForSupervisedDataset\n",
    "# 模拟 batch_size = 16\n",
    "batch_size = 6\n",
    "# 构造 batch 的输入样本列表\n",
    "features = [longest_sample] * batch_size  # 复制样本\n",
    "\n",
    "# 调用默认 collator（会处理 input_ids, attention_mask, labels）\n",
    "collator= DataCollatorForSupervisedDataset(tokenizer=tokenizer)\n",
    "batch = collator(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "668f6c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 取一个 batch\n",
    "# batch = next(iter(dataloader))  # 或者: for batch in dataloader:\n",
    "\n",
    "# 把数据移动到 GPU（确保模型也在 CUDA 上）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "input_ids = batch[\"input_ids\"].to(device)\n",
    "attention_mask = batch[\"attention_mask\"].to(device)\n",
    "labels = batch[\"labels\"].to(device)\n",
    "\n",
    "# 图像可能需要特殊处理（比如 list of tensors 或 Tensor）\n",
    "images = batch[\"images\"]\n",
    "images = [(item[0].to(device), item[1].to(device))\n",
    "          for item in images]\n",
    "# if isinstance(images, list):\n",
    "#     images = torch.stack(images)\n",
    "# images = images.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4520c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f83ef31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(input_ids.device)\n",
    "print(attention_mask.device)\n",
    "print(labels.device)\n",
    "print(images[0][1].device)\n",
    "print(next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58a1c37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "显存占用（训练前）: 2268.0 MB\n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |   2183 MiB |   2214 MiB |   2551 MiB | 377423 KiB |\n",
      "|       from large pool |   2181 MiB |   2212 MiB |   2548 MiB | 375808 KiB |\n",
      "|       from small pool |      1 MiB |      2 MiB |      2 MiB |   1615 KiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |   2183 MiB |   2214 MiB |   2551 MiB | 377423 KiB |\n",
      "|       from large pool |   2181 MiB |   2212 MiB |   2548 MiB | 375808 KiB |\n",
      "|       from small pool |      1 MiB |      2 MiB |      2 MiB |   1615 KiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |   2098 MiB |   2140 MiB |   2466 MiB | 377417 KiB |\n",
      "|       from large pool |   2096 MiB |   2138 MiB |   2463 MiB | 375808 KiB |\n",
      "|       from small pool |      1 MiB |      2 MiB |      2 MiB |   1609 KiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |   2268 MiB |   2268 MiB |   2268 MiB |      0 B   |\n",
      "|       from large pool |   2264 MiB |   2264 MiB |   2264 MiB |      0 B   |\n",
      "|       from small pool |      4 MiB |      4 MiB |      4 MiB |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |  84759 KiB | 121458 KiB |    997 MiB |    915 MiB |\n",
      "|       from large pool |  84096 KiB | 120704 KiB |    993 MiB |    911 MiB |\n",
      "|       from small pool |    663 KiB |   2416 KiB |      4 MiB |      3 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     487    |     487    |     668    |     181    |\n",
      "|       from large pool |     235    |     235    |     289    |      54    |\n",
      "|       from small pool |     252    |     252    |     379    |     127    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     487    |     487    |     668    |     181    |\n",
      "|       from large pool |     235    |     235    |     289    |      54    |\n",
      "|       from small pool |     252    |     252    |     379    |     127    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |     113    |     113    |     113    |       0    |\n",
      "|       from large pool |     111    |     111    |     111    |       0    |\n",
      "|       from small pool |       2    |       2    |       2    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      16    |      22    |      72    |      56    |\n",
      "|       from large pool |      14    |      19    |      69    |      55    |\n",
      "|       from small pool |       2    |       3    |       3    |       1    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 清空优化器梯度\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# 显存前\n",
    "print(\"显存占用（训练前）:\", torch.cuda.memory_reserved() / 1024**2, \"MB\")\n",
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a05aeffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_944694/2666483891.py:1: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: CausalLMOutputWithPast(loss=tensor(0.4377, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[[ 5.2305,  4.3984,  5.8164,  ..., -0.9219, -1.6182, -1.7695],\n",
      "         [ 5.4609,  4.6758,  6.1484,  ..., -0.7266, -1.4258, -1.7080],\n",
      "         [ 4.6328,  3.7129,  5.3047,  ..., -1.3828, -2.0488, -1.7646],\n",
      "         ...,\n",
      "         [20.1719, 16.2500, 17.0000,  ...,  7.8086, 14.9688, 11.0938],\n",
      "         [17.0625, 18.3438, 21.6875,  ..., 11.2422, 18.5312, 12.0625],\n",
      "         [16.7812, 16.2656, 19.4688,  ...,  6.0039, 14.3750,  7.7695]],\n",
      "\n",
      "        [[ 5.2305,  4.3984,  5.8164,  ..., -0.9219, -1.6182, -1.7695],\n",
      "         [ 5.4609,  4.6758,  6.1484,  ..., -0.7266, -1.4258, -1.7080],\n",
      "         [ 4.6328,  3.7129,  5.3047,  ..., -1.3828, -2.0488, -1.7646],\n",
      "         ...,\n",
      "         [20.1719, 16.2500, 17.0000,  ...,  7.8086, 14.9688, 11.0938],\n",
      "         [17.0625, 18.3438, 21.6875,  ..., 11.2422, 18.5312, 12.0625],\n",
      "         [16.7812, 16.2656, 19.4688,  ...,  6.0039, 14.3750,  7.7695]],\n",
      "\n",
      "        [[ 5.2305,  4.3984,  5.8164,  ..., -0.9219, -1.6182, -1.7695],\n",
      "         [ 5.4609,  4.6758,  6.1484,  ..., -0.7266, -1.4258, -1.7080],\n",
      "         [ 4.6328,  3.7129,  5.3047,  ..., -1.3828, -2.0488, -1.7646],\n",
      "         ...,\n",
      "         [20.1719, 16.2500, 17.0000,  ...,  7.8086, 14.9688, 11.0938],\n",
      "         [17.0625, 18.3438, 21.6875,  ..., 11.2422, 18.5312, 12.0625],\n",
      "         [16.7812, 16.2656, 19.4688,  ...,  6.0039, 14.3750,  7.7695]],\n",
      "\n",
      "        [[ 5.2305,  4.3984,  5.8164,  ..., -0.9219, -1.6182, -1.7695],\n",
      "         [ 5.4609,  4.6758,  6.1484,  ..., -0.7266, -1.4258, -1.7080],\n",
      "         [ 4.6328,  3.7129,  5.3047,  ..., -1.3828, -2.0488, -1.7646],\n",
      "         ...,\n",
      "         [20.1719, 16.2500, 17.0000,  ...,  7.8086, 14.9688, 11.0938],\n",
      "         [17.0625, 18.3438, 21.6875,  ..., 11.2422, 18.5312, 12.0625],\n",
      "         [16.7812, 16.2656, 19.4688,  ...,  6.0039, 14.3750,  7.7695]],\n",
      "\n",
      "        [[ 5.2305,  4.3984,  5.8164,  ..., -0.9219, -1.6182, -1.7695],\n",
      "         [ 5.4609,  4.6758,  6.1484,  ..., -0.7266, -1.4258, -1.7080],\n",
      "         [ 4.6328,  3.7129,  5.3047,  ..., -1.3828, -2.0488, -1.7646],\n",
      "         ...,\n",
      "         [20.1719, 16.2500, 17.0000,  ...,  7.8086, 14.9688, 11.0938],\n",
      "         [17.0625, 18.3438, 21.6875,  ..., 11.2422, 18.5312, 12.0625],\n",
      "         [16.7812, 16.2656, 19.4688,  ...,  6.0039, 14.3750,  7.7695]],\n",
      "\n",
      "        [[ 5.2305,  4.3984,  5.8164,  ..., -0.9219, -1.6182, -1.7695],\n",
      "         [ 5.4609,  4.6758,  6.1484,  ..., -0.7266, -1.4258, -1.7080],\n",
      "         [ 4.6328,  3.7129,  5.3047,  ..., -1.3828, -2.0488, -1.7646],\n",
      "         ...,\n",
      "         [20.1719, 16.2500, 17.0000,  ...,  7.8086, 14.9688, 11.0938],\n",
      "         [17.0625, 18.3438, 21.6875,  ..., 11.2422, 18.5312, 12.0625],\n",
      "         [16.7812, 16.2656, 19.4688,  ...,  6.0039, 14.3750,  7.7695]]],\n",
      "       device='cuda:0', grad_fn=<ToCopyBackward0>), past_key_values=<transformers.cache_utils.DynamicCache object at 0x7f9454328370>, hidden_states=None, attentions=None)\n",
      "Loss: 0.4376753270626068\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 3.12 GiB. GPU 0 has a total capacity of 23.57 GiB of which 2.37 GiB is free. Including non-PyTorch memory, this process has 21.17 GiB memory in use. Of the allocated memory 20.58 GiB is allocated by PyTorch, and 293.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# 反向传播 + 更新参数\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# 显存后\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/got/lib/python3.10/site-packages/torch/_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    647\u001b[0m     )\n\u001b[0;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/got/lib/python3.10/site-packages/torch/autograd/__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/got/lib/python3.10/site-packages/torch/autograd/graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 3.12 GiB. GPU 0 has a total capacity of 23.57 GiB of which 2.37 GiB is free. Including non-PyTorch memory, this process has 21.17 GiB memory in use. Of the allocated memory 20.58 GiB is allocated by PyTorch, and 293.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "with torch.cuda.amp.autocast():\n",
    "    outputs = model(input_ids=input_ids,\n",
    "                    attention_mask=attention_mask, labels=labels, images=images)\n",
    "    print(\"outputs:\", outputs)\n",
    "    loss = outputs.loss\n",
    "# loss = outputs.loss\n",
    "print(\"Loss:\", loss.item())\n",
    "\n",
    "# 反向传播 + 更新参数\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "# 显存后\n",
    "print(\"显存占用（训练后）:\", torch.cuda.memory_allocated() / 1024**2, \"MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bee9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 1         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |  11122 MiB |  21514 MiB | 182150 MiB | 171027 MiB |\n",
      "|       from large pool |  11120 MiB |  21501 MiB | 181596 MiB | 170476 MiB |\n",
      "|       from small pool |      2 MiB |     19 MiB |    554 MiB |    551 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |  11122 MiB |  21514 MiB | 182150 MiB | 171027 MiB |\n",
      "|       from large pool |  11120 MiB |  21501 MiB | 181596 MiB | 170476 MiB |\n",
      "|       from small pool |      2 MiB |     19 MiB |    554 MiB |    551 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |  10932 MiB |  21406 MiB | 181361 MiB | 170428 MiB |\n",
      "|       from large pool |  10930 MiB |  21392 MiB | 180807 MiB | 169877 MiB |\n",
      "|       from small pool |      2 MiB |     19 MiB |    553 MiB |    550 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |  19144 MiB |  23330 MiB |  26112 MiB |   6968 MiB |\n",
      "|       from large pool |  19124 MiB |  23310 MiB |  26092 MiB |   6968 MiB |\n",
      "|       from small pool |     20 MiB |     20 MiB |     20 MiB |      0 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |   3643 MiB |   5831 MiB |  44653 MiB |  41009 MiB |\n",
      "|       from large pool |   3635 MiB |   5824 MiB |  44071 MiB |  40435 MiB |\n",
      "|       from small pool |      7 MiB |     10 MiB |    581 MiB |    574 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |    1419    |    1711    |   10433    |    9014    |\n",
      "|       from large pool |     800    |     970    |    6838    |    6038    |\n",
      "|       from small pool |     619    |     741    |    3595    |    2976    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |    1419    |    1711    |   10433    |    9014    |\n",
      "|       from large pool |     800    |     970    |    6838    |    6038    |\n",
      "|       from small pool |     619    |     741    |    3595    |    2976    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |     424    |     427    |     428    |       4    |\n",
      "|       from large pool |     414    |     417    |     418    |       4    |\n",
      "|       from small pool |      10    |      10    |      10    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |     256    |     274    |    5116    |    4860    |\n",
      "|       from large pool |     215    |     237    |    4054    |    3839    |\n",
      "|       from small pool |      41    |      47    |    1062    |    1021    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45fde97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 16\n",
    "# seq_len = 200\n",
    "\n",
    "# # 模拟input_ids：随机生成在词表大小范围内\n",
    "# vocab_size = model.config.vocab_size\n",
    "# input_ids = torch.randint(low=0, high=vocab_size, size=(\n",
    "#     batch_size, seq_len), device=device)\n",
    "\n",
    "# # 模拟attention_mask：全1\n",
    "# attention_mask = torch.ones_like(input_ids, device=device)\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "# # 模拟labels（可以和input_ids相同，也可部分设-100忽略loss）\n",
    "# labels = input_ids.clone()\n",
    "# labels[:, :10] = -100\n",
    "\n",
    "# # 模拟 images 输入（batch内每个样本含1张图像，1个patch，3通道1024x1024）\n",
    "# # GOT代码里图像输入是一个list，列表长度为batch_size，每个元素形如(image_count, 3, H, W)\n",
    "# # 这里image_count=1, 高度宽度为1024\n",
    "# images = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c359ddea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# for _ in range(batch_size):\n",
    "#     img_tensor = torch.randn(1, 3, 1024, 1024, device=device, dtype=torch.float32)  # 模拟单张图像\n",
    "#     images.append((None, img_tensor))  # 你的代码中传入的images元素形如 tuple，第二项是Tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c222d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe9c6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(images[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef383319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 记录显存占用\n",
    "# print(\"显存占用（训练前）:\", torch.cuda.memory_allocated() / 1024**2, \"MB\")\n",
    "\n",
    "# optimizer.zero_grad()\n",
    "\n",
    "# outputs = model(\n",
    "#     input_ids=input_ids,\n",
    "#     attention_mask=attention_mask,\n",
    "#     labels=labels,\n",
    "#     images=images,\n",
    "#     return_dict=True,\n",
    "# )\n",
    "\n",
    "# loss = outputs.loss\n",
    "# print(\"Loss:\", loss.item())\n",
    "\n",
    "# loss.backward()\n",
    "\n",
    "# optimizer.step()\n",
    "\n",
    "# print(\"显存占用（训练后）:\", torch.cuda.memory_allocated() / 1024**2, \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9c6ae4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "got",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
